{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: gensim in c:\\users\\misha\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (4.3.2)Note: you may need to restart the kernel to use updated packages.\n",
      "\n",
      "Requirement already satisfied: numpy>=1.18.5 in c:\\users\\misha\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from gensim) (1.26.1)\n",
      "Requirement already satisfied: scipy>=1.7.0 in c:\\users\\misha\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from gensim) (1.11.3)\n",
      "Requirement already satisfied: smart-open>=1.8.1 in c:\\users\\misha\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from gensim) (6.4.0)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 23.2.1 -> 23.3.1\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting word2vecNote: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  error: subprocess-exited-with-error\n",
      "  \n",
      "  × Building wheel for word2vec (pyproject.toml) did not run successfully.\n",
      "  │ exit code: 1\n",
      "  ╰─> [130 lines of output]\n",
      "      running bdist_wheel\n",
      "      running build\n",
      "      running build_py\n",
      "      creating build\n",
      "      creating build\\lib\n",
      "      creating build\\lib\\word2vec\n",
      "      copying word2vec\\io.py -> build\\lib\\word2vec\n",
      "      copying word2vec\\scripts_interface.py -> build\\lib\\word2vec\n",
      "      copying word2vec\\utils.py -> build\\lib\\word2vec\n",
      "      copying word2vec\\wordclusters.py -> build\\lib\\word2vec\n",
      "      copying word2vec\\wordvectors.py -> build\\lib\\word2vec\n",
      "      copying word2vec\\_generated_version.py -> build\\lib\\word2vec\n",
      "      copying word2vec\\__init__.py -> build\\lib\\word2vec\n",
      "      creating build\\lib\\word2vec\\tests\n",
      "      copying word2vec\\tests\\test_core.py -> build\\lib\\word2vec\\tests\n",
      "      copying word2vec\\tests\\test_import.py -> build\\lib\\word2vec\\tests\n",
      "      copying word2vec\\tests\\test_scripts_present.py -> build\\lib\\word2vec\\tests\n",
      "      copying word2vec\\tests\\__init__.py -> build\\lib\\word2vec\\tests\n",
      "      running egg_info\n",
      "      writing word2vec.egg-info\\PKG-INFO\n",
      "      writing dependency_links to word2vec.egg-info\\dependency_links.txt\n",
      "      writing requirements to word2vec.egg-info\\requires.txt\n",
      "      writing top-level names to word2vec.egg-info\\top_level.txt\n",
      "      ERROR setuptools_scm._file_finders.git listing git files failed - pretending there aren't any\n",
      "      reading manifest file 'word2vec.egg-info\\SOURCES.txt'\n",
      "      adding license file 'LICENSE.txt'\n",
      "      writing manifest file 'word2vec.egg-info\\SOURCES.txt'\n",
      "      C:\\Users\\misha\\AppData\\Local\\Temp\\pip-build-env-_17hieqg\\overlay\\Lib\\site-packages\\setuptools\\command\\build_py.py:204: _Warning: Package 'word2vec.includes' is absent from the `packages` configuration.\n",
      "      !!\n",
      "      \n",
      "              ********************************************************************************\n",
      "              ############################\n",
      "              # Package would be ignored #\n",
      "              ############################\n",
      "              Python recognizes 'word2vec.includes' as an importable package[^1],\n",
      "              but it is absent from setuptools' `packages` configuration.\n",
      "      \n",
      "              This leads to an ambiguous overall configuration. If you want to distribute this\n",
      "              package, please make sure that 'word2vec.includes' is explicitly added\n",
      "              to the `packages` configuration field.\n",
      "      \n",
      "              Alternatively, you can also rely on setuptools' discovery methods\n",
      "              (for example by using `find_namespace_packages(...)`/`find_namespace:`\n",
      "              instead of `find_packages(...)`/`find:`).\n",
      "      \n",
      "              You can read more about \"package discovery\" on setuptools documentation page:\n",
      "      \n",
      "              - https://setuptools.pypa.io/en/latest/userguide/package_discovery.html\n",
      "      \n",
      "              If you don't want 'word2vec.includes' to be distributed and are\n",
      "              already explicitly excluding 'word2vec.includes' via\n",
      "              `find_namespace_packages(...)/find_namespace` or `find_packages(...)/find`,\n",
      "              you can try to use `exclude_package_data`, or `include-package-data=False` in\n",
      "              combination with a more fine grained `package-data` configuration.\n",
      "      \n",
      "              You can read more about \"package data files\" on setuptools documentation page:\n",
      "      \n",
      "              - https://setuptools.pypa.io/en/latest/userguide/datafiles.html\n",
      "      \n",
      "      \n",
      "              [^1]: For Python, any directory (with suitable naming) can be imported,\n",
      "                    even if it does not contain any `.py` files.\n",
      "                    On the other hand, currently there is no concept of package data\n",
      "                    directory, all directories are treated like packages.\n",
      "              ********************************************************************************\n",
      "      \n",
      "      !!\n",
      "        check.warn(importable)\n",
      "      C:\\Users\\misha\\AppData\\Local\\Temp\\pip-build-env-_17hieqg\\overlay\\Lib\\site-packages\\setuptools\\command\\build_py.py:204: _Warning: Package 'word2vec.includes.win32' is absent from the `packages` configuration.\n",
      "      !!\n",
      "      \n",
      "              ********************************************************************************\n",
      "              ############################\n",
      "              # Package would be ignored #\n",
      "              ############################\n",
      "              Python recognizes 'word2vec.includes.win32' as an importable package[^1],\n",
      "              but it is absent from setuptools' `packages` configuration.\n",
      "      \n",
      "              This leads to an ambiguous overall configuration. If you want to distribute this\n",
      "              package, please make sure that 'word2vec.includes.win32' is explicitly added\n",
      "              to the `packages` configuration field.\n",
      "      \n",
      "              Alternatively, you can also rely on setuptools' discovery methods\n",
      "              (for example by using `find_namespace_packages(...)`/`find_namespace:`\n",
      "              instead of `find_packages(...)`/`find:`).\n",
      "      \n",
      "              You can read more about \"package discovery\" on setuptools documentation page:\n",
      "      \n",
      "              - https://setuptools.pypa.io/en/latest/userguide/package_discovery.html\n",
      "      \n",
      "              If you don't want 'word2vec.includes.win32' to be distributed and are\n",
      "              already explicitly excluding 'word2vec.includes.win32' via\n",
      "              `find_namespace_packages(...)/find_namespace` or `find_packages(...)/find`,\n",
      "              you can try to use `exclude_package_data`, or `include-package-data=False` in\n",
      "              combination with a more fine grained `package-data` configuration.\n",
      "      \n",
      "              You can read more about \"package data files\" on setuptools documentation page:\n",
      "      \n",
      "              - https://setuptools.pypa.io/en/latest/userguide/datafiles.html\n",
      "      \n",
      "      \n",
      "              [^1]: For Python, any directory (with suitable naming) can be imported,\n",
      "                    even if it does not contain any `.py` files.\n",
      "                    On the other hand, currently there is no concept of package data\n",
      "                    directory, all directories are treated like packages.\n",
      "              ********************************************************************************\n",
      "      \n",
      "      !!\n",
      "        check.warn(importable)\n",
      "      creating build\\lib\\word2vec\\includes\n",
      "      copying word2vec\\includes\\Makefile -> build\\lib\\word2vec\\includes\n",
      "      copying word2vec\\includes\\compute-accuracy.c -> build\\lib\\word2vec\\includes\n",
      "      copying word2vec\\includes\\distance.c -> build\\lib\\word2vec\\includes\n",
      "      copying word2vec\\includes\\word-analogy.c -> build\\lib\\word2vec\\includes\n",
      "      copying word2vec\\includes\\word2phrase.c -> build\\lib\\word2vec\\includes\n",
      "      copying word2vec\\includes\\word2vec-sentence2vec.c -> build\\lib\\word2vec\\includes\n",
      "      copying word2vec\\includes\\word2vec.c -> build\\lib\\word2vec\\includes\n",
      "      creating build\\lib\\word2vec\\includes\\win32\n",
      "      copying word2vec\\includes\\win32\\Makefile -> build\\lib\\word2vec\\includes\\win32\n",
      "      copying word2vec\\includes\\win32\\compute-accuracy.c -> build\\lib\\word2vec\\includes\\win32\n",
      "      copying word2vec\\includes\\win32\\distance.c -> build\\lib\\word2vec\\includes\\win32\n",
      "      copying word2vec\\includes\\win32\\win32-port.h -> build\\lib\\word2vec\\includes\\win32\n",
      "      copying word2vec\\includes\\win32\\word-analogy.c -> build\\lib\\word2vec\\includes\\win32\n",
      "      copying word2vec\\includes\\win32\\word2phrase.c -> build\\lib\\word2vec\\includes\\win32\n",
      "      copying word2vec\\includes\\win32\\word2vec.c -> build\\lib\\word2vec\\includes\\win32\n",
      "      installing to build\\bdist.win-amd64\\wheel\n",
      "      running install\n",
      "      Running custom Install command\n",
      "      Compiling: gcc C:\\Users\\misha\\AppData\\Local\\Temp\\pip-install-cr6izakn\\word2vec_01dbd5342d254ecbbdb84e5c9ae7f1b8\\word2vec\\includes\\win32/word2vec.c -o Scripts\\word2vec.exe -O2 -Wall -funroll-loops\n",
      "      error: [WinError 2] РќРµ СѓРґР°РµС‚СЃСЏ РЅР°Р№С‚Рё СѓРєР°Р·Р°РЅРЅС‹Р№ С„Р°Р№Р»\n",
      "      [end of output]\n",
      "  \n",
      "  note: This error originates from a subprocess, and is likely not a problem with pip.\n",
      "  ERROR: Failed building wheel for word2vec\n",
      "ERROR: Could not build wheels for word2vec, which is required to install pyproject.toml-based projects\n",
      "\n",
      "[notice] A new release of pip is available: 23.2.1 -> 23.3.1\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "  Using cached word2vec-0.11.1.tar.gz (42 kB)\n",
      "  Installing build dependencies: started\n",
      "  Installing build dependencies: finished with status 'done'\n",
      "  Getting requirements to build wheel: started\n",
      "  Getting requirements to build wheel: finished with status 'done'\n",
      "  Preparing metadata (pyproject.toml): started\n",
      "  Preparing metadata (pyproject.toml): finished with status 'done'\n",
      "Requirement already satisfied: numpy>=1.9.2 in c:\\users\\misha\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from word2vec) (1.26.1)\n",
      "Requirement already satisfied: joblib in c:\\users\\misha\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from word2vec) (1.3.2)\n",
      "Building wheels for collected packages: word2vec\n",
      "  Building wheel for word2vec (pyproject.toml): started\n",
      "  Building wheel for word2vec (pyproject.toml): finished with status 'error'\n",
      "Failed to build word2vec\n"
     ]
    }
   ],
   "source": [
    "%pip install gensim\n",
    "%pip install word2vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gensim.downloader\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['fasttext-wiki-news-subwords-300',\n",
       " 'conceptnet-numberbatch-17-06-300',\n",
       " 'word2vec-ruscorpora-300',\n",
       " 'word2vec-google-news-300',\n",
       " 'glove-wiki-gigaword-50',\n",
       " 'glove-wiki-gigaword-100',\n",
       " 'glove-wiki-gigaword-200',\n",
       " 'glove-wiki-gigaword-300',\n",
       " 'glove-twitter-25',\n",
       " 'glove-twitter-50',\n",
       " 'glove-twitter-100',\n",
       " 'glove-twitter-200',\n",
       " '__testing_word2vec-matrix-synopsis']"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(gensim.downloader.info()['models'].keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[==================================================] 100.0% 1662.8/1662.8MB downloaded\n"
     ]
    }
   ],
   "source": [
    "w2v_eng = gensim.downloader.load('word2vec-google-news-300')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "word #0/3000000 is </s>\n",
      "word #1/3000000 is in\n",
      "word #2/3000000 is for\n",
      "word #3/3000000 is that\n",
      "word #4/3000000 is is\n",
      "word #5/3000000 is on\n",
      "word #6/3000000 is ##\n",
      "word #7/3000000 is The\n",
      "word #8/3000000 is with\n",
      "word #9/3000000 is said\n"
     ]
    }
   ],
   "source": [
    "for index, word in enumerate(w2v_eng.index_to_key ):\n",
    "    if index == 10:\n",
    "        break\n",
    "    print(f\"word #{index}/{len(w2v_eng.index_to_key )} is {word}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('females', 'males'), ('males', 'females'), ('Female', 'Male'), ('accomplice_Hudgens', 'DBCP_pesticide_scientists'), ('Male', 'Males'), ('femal', 'males'), ('Gestapo_massacred', 'Lidice_Czechoslovakia'), ('DBCP_pesticide_scientists', 'accomplice_Hudgens'), ('Gender_bender', 'accomplice_Hudgens'), ('panda_Gao_Gao', 'accomplice_Hudgens'), ('women', 'men'), ('XX_chromosomes', 'XY_chromosomes'), ('sexually_objectified', 'masculinised'), ('companions_Khin_Khin', 'males'), ('sex_hormones_androgens', 'androgen_hormone'), (\"#'##_#'##_tall\", \"#'#_#'#_tall\"), ('singer_Dea_Norberg', 'accomplice_Hudgens'), ('masculinised', 'masculine_traits'), ('hormone_androgen', 'male_hormone_androgen'), ('flight_attendant_tackled_Almurisi', 'accomplice_Hudgens'), ('heterosexual_males', 'males'), ('dark_complected_black', \"#'#_#'#_tall\"), ('endocrinologist_psychologist', 'accomplice_Hudgens'), ('woman', 'man'), (\"DEAR_ELLIE_I'ma\", \"DEAR_ABBY_I'ma\"), ('Caucasian_males', 'males'), ('genitally', 'heterosexually'), ('swordtails', 'males'), ('biochemist_Peggy_Whitson', 'accomplice_Hudgens'), ('captive_Faye_Turney', 'accomplice_Hudgens'), ('vocal_ensemble_Cantus', 'cappella_ensemble'), (\"QI'ma\", \"DEAR_ELLIE_I'ma\"), ('middle_aged', 'Sayed_Wakhan_sunburned'), ('gender', 'Gender'), ('butch_lesbian', 'hypermasculine'), ('macho_Expendables_lured', 'accomplice_Hudgens'), ('Farida_Deif', 'accomplice_Hudgens'), ('officer_Ayez', 'accomplice_Hudgens'), ('acquaintance_Yelena_Bulchenko', 'accomplice_Hudgens'), ('contain_sulfoaildenafil', 'accomplice_Hudgens'), ('transsexuals_transvestites', 'crossdressers'), ('hypermasculine', 'hyper_masculine'), ('spokeswoman_Thalia_Schweizer', 'Solothurn_cantonal'), ('Steve_Desjourdy', 'alleged_stabber'), ('transwomen', 'males'), ('rapper_MC_Lyte', 'accomplice_Hudgens'), ('masculinized', 'masculinised'), ('nonwhite', 'nonblack'), ('bowerbird', 'bowerbirds'), ('Females', 'Males'), ('named_Aoyun', 'accomplice_Hudgens'), ('Skutella', 'germline_stem_cells'), ('trim_shapely_body', 'accomplice_Hudgens'), ('Labrador_chow', 'cocker_spaniel_poodle'), ('XY_chromosomes', 'masculine_traits'), ('pharaoh_Queen_Hatshepsut', 'accomplice_Hudgens'), ('faking_orgasms', 'fake_orgasms'), ('fake_orgasms', 'visually_stimulated'), ('Massa_groped', 'accomplice_Hudgens'), ('behaving_inappropriately_towards', 'accomplice_Hudgens'), ('supermodel_Tyson_Beckford', 'model_Tyson_Beckford'), ('male_lampreys', 'scents_emitted'), ('Dresses_sewed', 'males'), ('Caucasian', 'caucasian'), ('intersexed', 'intersexual'), ('aviators_dehydration', 'accomplice_Hudgens'), ('butches', 'crossdressers'), ('reporter_Sanga_Amaaj', 'accomplice_Hudgens'), ('Nicole_Biancofiore_wrote', 'males'), ('border_collie_Doberman', 'accomplice_Hudgens'), ('heterosexual', 'heterosexuals'), ('Yesenia_Pereyda_Martinez', 'accomplice_Hudgens'), ('virile_reproductive', 'accomplice_Hudgens'), ('wives_mistresses', 'boyfriends_husbands'), ('thong_clad', 'hairy_chests'), ('genetically_altered_sterile', 'Gestapo_massacred'), ('Caucasion', 'caucasian'), ('traveler_Valentina_Tereshkova', 'accomplice_Hudgens'), ('caucasion', 'caucasian'), ('blonde_brunette', 'blond_brunette'), ('middleaged', 'middle_aged'), ('skimpily_dressed', 'skimpily_clad'), ('marathoner_Chong', 'males'), ('sexes', 'genders'), ('manakin', 'pileated'), ('Moiseff', 'males'), ('stereotypically_male', 'masculine_traits'), ('Samantha_Booke_Jurnee_Smollett', 'By_Soh_Ji'), ('Col._Shafiqa', 'gender'), ('HPV_vaccine_workgroup', 'preventing_genital_warts'), ('Males', 'males'), ('dilute_calico', 'white_domestic_shorthair'), (\"DEAR_ABBY_I'ma\", \"DEAR_ELLIE_I'ma\"), ('Houston_Marmion_Dambrino', 'males'), ('Munwha_Ilbo_newspaper', 'accomplice_Hudgens'), ('Sayed_Wakhan_sunburned', 'middle_aged'), ('correspondent_Olivia_Munn', 'accomplice_Hudgens'), ('Manila_DZBB_radio', 'accomplice_Hudgens'), ('scantly_clad', 'bodacious_babes'), ('feminine_traits', 'masculine_traits')]\n"
     ]
    }
   ],
   "source": [
    "with open(\"mazymay.txt\", \"r\") as file:\n",
    "    texts = file.read().splitlines()\n",
    "\n",
    "# Поиск слов, наиболее близких к \"мужчина-женщина\"\n",
    "most_similar_words = w2v_eng.most_similar(positive=['male', 'female'], topn=100)\n",
    "\n",
    "# Создание списка пар слов вида \"мужчина-женщина\" и их аналогий\n",
    "analogies = []\n",
    "for word, similarity in most_similar_words:\n",
    "    analogy = (word, w2v_eng.most_similar(positive=['male', word], negative=['female'], topn=1)[0][0])\n",
    "    analogies.append(analogy)\n",
    "\n",
    "print(analogies)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
